\documentclass[a4paper,11pt,twocolumn,twoside]{article}
\usepackage[dvips]{graphicx}
\usepackage{sepln_en}
\usepackage{fullname}
\usepackage[utf8]{inputenc}
% \usepackage[spanish,es-nosectiondot, es-tabla, es-noindentfirst, es-nolists]{babel}

\input epsf

\setlength\titlebox{4in} %esto por defecto

\title{Overview of the eHealth Knowledge Discovery Challenge at IberLEF 2021}

\author {\textbf{Nombre Apellidos1,$^1$} \textbf{Nombre Apellidos2$^2$}\\
$^1$Universidad o lugar de trabajo\\
$^2$Universidad o lugar de trabajo\\
Información de contacto\\
}

\seplntranstitle{Resumen de la Tarea de Descubrimiento de Conocimiento en Salud en IberLEF 2021}

\seplnclave{Palabras, palabras, palabras en castellano...}

\seplnresumen{Resumen del artículo en castellano con una sangría a izquierda y
derecha de 1 cm, justificado por ambos lados, con tamaño de fuente
11.}


\seplnkey{Palabras, palabras, palabras en inglés...}

\seplnabstract{Resumen del artículo en inglés con una sangría a izquierda y
derecha de 1 cm, justificado por ambos lados, con tamaño de fuente
11.}

\firstpageno{1}

\begin{document}

% la siguiente instrucción sólo se debe usar si el abstract sobrescribe el texto
% la longitud variará según se necesite

%\setlength\titlebox{20cm} % se aumenta el tamaño del espacio reservado para datos de título

\label{firstpage} \maketitle

%\begin{abstract}
%Resumen del artículo con una sangría a izquierda y derecha de 0.32
%cm, justificado por ambos lados, con tamaño de fuente 11.
%
%\end{abstract}

\section{Introduction}


The accelerated growth of the Internet and the increased production of textual resources in all areas of human endeavour has created both new opportunities and new challenges for the research community.
On one hand, larger datasets can be collected and used to build increasingly powerful machine learning models~(e.g., GPT-3 and related).
On the other hand, is becoming increasingly difficult to organise, categorise, cross-reference, and fact-check the textual information available online.
The ease of access to both publication and consumption of textual information is arguably one of the root causes of the increasingly worrying phenomenon of fake news.

Staying up-to-date on information about topics of interest is crucial in technical or scientific domains.
For this purpose, specialists rely on a combination of curated soruces (e.g., domain-specific repositories like arxiv, bioarxiv, semantic scholar) and technologies for search and recommendation (e.g., google scholar).
These resources significantly improve the experience of collecting and consuming large amounts of relevant information on a specific topic.
Tools like Connected Papers~\cite{} and Papers with Code~\cite{} are one step beyond the indexing of documents, providing summarised and structured representations of the content in a collection of documents.
However, it remains an open problem to automatically combine, summarise, and present the relevant information in a collection of documents in a semantic structure~(e.g., a knowledge graph) that allows a specialist to quickly grasp the essential concepts of a specific knowledge field.

A potential solution to this problem would require methods to automatically detect in natural language the most relevant concepts and the factual statements in which they are related, possibly normalise them into well-established taxonomies and classifications, and store them in computational data structures where they can linked with related concepts, e.g., knowledge graphs.
The first step of this process, i.e., the detection of relevant concepts and semantic relations in text, is already a challenging computational task, given the complexity and variability of natural language.
To encourage research and development in this area, several academic competitions have been organised through the years by organizations such as CLEF, SEMEVAL, and more recently, IBERLEF.

In this context, the eHealth Knowledge Discovery Challenge is designed to foster the development of automatic knowledge discovery systems for natural language sentences in a cross-domain and multi-lingual setting.
Concretely, a token-level annotation model of 4 entities and 13 semantic relations is defined, and a corpus of more than 1500 sentences from different factual sources~(i.e., Spanish Medline articles, Spanish Wikinews articles, and English biomedical preprints related to COVID-19) is annotated.
Two computational tasks are defined: the detection of multi-span, non-contiguous, and potentially overlapping named entities; and the detection of semantic relations between them.
A shared annotation campaign was organized, where a total of 9 participants presented 10 different systems with varied levels of performance.

The eHealth-KD task focuses on cross-domain, multi-lingual and low-resource solutions. This setting presents a significant challenge to existing state-of-the-art methods, which often rely on large amounts of training data.
A succesful approach to the eHealth-KD must leverage transfer learning across both different domains and languages, since the vast majority of the training examples are provided in Spanish language and Medline articles, while only a small development set is available in the remaining settings.
With this added complexity, we expect to encourage solutions that can be deployed in low-resource environments, where is unfeasible to train large language models over longs periods of time.

The remaining of this paper is organized as follows.
Section~\ref{sec:task} describes the eHealth-KD tasks in greater detail, including the annotation model and performance metrics.
Section~\ref{sec:resources} describes the corpora and other resources created for this challenge and presents some qualitative analysis of their characteristics.
Section~\ref{sec:systems} describes the different systems presented in the challenge and summarises the main approaches and most common characteristics they share.
Section~\ref{sec:results} presents the main results of the challenge.
Section~\ref{sec:discussion} discusses the most interesting insights of the challenge and highlights both the most relevant lessons learned and potential improvements for future similar endeavours.

\section{Tasks Descriptions}\label{sec:task}

The eHealth-KD challenge consists on the automatic sentence-level annotation
of multi-token entities and binary relations among them.

A custom annotation model has been defined, comprising 4 entity types and 13 relations,
that attempts to capture a large part of factual semantics in technical documents,
including enciclopedias, news, and scientific papers.

The annotation model is explained in detail in \namecite{piad2019general}.

A brief explanation is presented next.

-- Explicar las entidades y relaciones como siempre.

The challenge has been divided into two different subtasks:
entity recognition and relation extraction.

To evaluate each subtask, we count correct, partial, missing, and spurious
annotations, and weight them according to an $F_1$ measure, independently per task.

-- Fórmulas

Furthermore, the challenge is graded in three different scenarios:
one for each subtask and one where both subtasks are performed in sequence.
This is the main scenario, which ultimately decides the winner of the challenge,
although all other results are interesting.

\section{Corpora and Resources}\label{sec:resources}

The Challenge is based on a corpus of documents composed of
sentences taken from previous challenges and other resources,
and newly annotated sentences.

Three different sources of textual information are sampled: medline articles,
wikinews articles, and biomedical papers from the CORD-19 corpus.

The medline and wikinews articles are in Spanish, while CORD are in English.

From the 2019 and 2020 challenges, X sentences where taken.

For this new edition, Y sentences were annotated by a team of annotators.
The team composition is 4 junior annotators and 3 senior annotators.
2 junior annotators annotated each sentence, and a senior annotator performed the merging.

The newly annotated sentences are used solely for evaluation purposes,
while all training and development resources are reused from previous challenges.

Overall, the composition of the corpus is presented in Table~\ref{tab:corpus}.

\begin{table}
  \caption{Composition of the corpus, highlighting resources from previous
  challenges and newly annotated sentences.\label{tab:corpus}}
\end{table}

\section{Systems Descriptions}\label{sec:systems}
´
The challenge caught the attention of 8 participants from across the globe,
who presented a variety of approaches clustered around deep learning architectures.

-- Describir los sistemas

\section{Challenge Results}\label{sec:results}

Table~\ref{tab:results} summarizes the main results in the challenge.

\begin{table}
  \caption{Results.\label{tab:results}}
\end{table}

In Scenario 1, the best performing system is\dots

-- Describir los demás escenarios

\section{Discussion}\label{sec:discussion}

-- Ver los sistemas con sus features y qué features son mejores o peores en cada tarea

-- Comparar con los baselines en cada tarea, hasta qué nivel está resuelta cada tarea

-- Hablar brevemente de la evolución de los sistemas en las 4 ediciones,
cómo se han ido moviendo hacia transformers

-- Hablar de la modelación de las entidades y relaciones como tareas separadas,
la desventaja que puede representar eso porque los sistemas que han ganado hacen
ambas cosas a la vez, o sea hay representación conjunta que es válida

-- Hablar de las relaciones como problema binario, que no tiene en cuenta que ciertas
relaciones implican posiblemente la aparición de otras.

-- Hablar de que el orden en que el humano anota no es el mismo que un sistema,
y que si se pudiera aprender algo de esto, dar con el dataset no solo las anotaciones
sino en qué orden fueron realizadas.

-- Hablar de la necesidad de cambiar de tareas hacia algo que refleje el valor
del conocimiento extraído, como question answering.

\section{Conclusions}\label{sec:conclusions}

\section*{Acknowledgments}

\bibliographystyle{fullname}
\bibliography{bibliography}

\end{document}
