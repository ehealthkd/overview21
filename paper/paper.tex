\documentclass[a4paper,11pt,twocolumn,twoside]{article}
\usepackage[dvips]{graphicx}
\usepackage{sepln_en}
\usepackage{fullname}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{tabularx}
% \usepackage[spanish,es-nosectiondot, es-tabla, es-noindentfirst, es-nolists]{babel}

\input epsf

\setlength\titlebox{4in} %esto por defecto

\title{Overview of the eHealth Knowledge Discovery Challenge at IberLEF 2021}

\author {\textbf{Nombre Apellidos1,$^1$} \textbf{Nombre Apellidos2$^2$}\\
$^1$Universidad o lugar de trabajo\\
$^2$Universidad o lugar de trabajo\\
Información de contacto\\
}

\seplntranstitle{Resumen de la Tarea de Descubrimiento de Conocimiento en Salud en IberLEF 2021}

\seplnclave{Palabras, palabras, palabras en castellano...}

\seplnresumen{Resumen del artículo en castellano con una sangría a izquierda y
derecha de 1 cm, justificado por ambos lados, con tamaño de fuente
11.}


\seplnkey{Palabras, palabras, palabras en inglés...}

\seplnabstract{Resumen del artículo en inglés con una sangría a izquierda y
derecha de 1 cm, justificado por ambos lados, con tamaño de fuente
11.}

\firstpageno{1}

\begin{document}

% la siguiente instrucción sólo se debe usar si el abstract sobrescribe el texto
% la longitud variará según se necesite

%\setlength\titlebox{20cm} % se aumenta el tamaño del espacio reservado para datos de título

\label{firstpage} \maketitle

%\begin{abstract}
%Resumen del artículo con una sangría a izquierda y derecha de 0.32
%cm, justificado por ambos lados, con tamaño de fuente 11.
%
%\end{abstract}

\section{Introduction}


The accelerated growth of the Internet and the increased production of textual resources in all areas of human endeavour has created both new opportunities and new challenges for the research community.
On one hand, larger datasets can be collected and used to build increasingly powerful machine learning models~(e.g., GPT-3 and related).
On the other hand, is becoming increasingly difficult to organise, categorise, cross-reference, and fact-check the textual information available online.
The ease of access to both publication and consumption of textual information is arguably one of the root causes of the increasingly worrying phenomenon of fake news.

Staying up-to-date on information about topics of interest is crucial in technical or scientific domains.
For this purpose, specialists rely on a combination of curated soruces (e.g., domain-specific repositories like arxiv, bioarxiv, semantic scholar) and technologies for search and recommendation (e.g., google scholar).
These resources significantly improve the experience of collecting and consuming large amounts of relevant information on a specific topic.
Tools like Connected Papers~\cite{} and Papers with Code~\cite{} are one step beyond the indexing of documents, providing summarised and structured representations of the content in a collection of documents.
However, it remains an open problem to automatically combine, summarise, and present the relevant information in a collection of documents in a semantic structure~(e.g., a knowledge graph) that allows a specialist to quickly grasp the essential concepts of a specific knowledge field.

A potential solution to this problem would require methods to automatically detect in natural language the most relevant concepts and the factual statements in which they are related, possibly normalise them into well-established taxonomies and classifications, and store them in computational data structures where they can linked with related concepts, e.g., knowledge graphs.
The first step of this process, i.e., the detection of relevant concepts and semantic relations in text, is already a challenging computational task, given the complexity and variability of natural language.
To encourage research and development in this area, several academic competitions have been organised through the years by organizations such as CLEF, SEMEVAL, and more recently, IBERLEF.

In this context, the eHealth Knowledge Discovery Challenge is designed to foster the development of automatic knowledge discovery systems for natural language sentences in a cross-domain and multi-lingual setting.
Concretely, a token-level annotation model of 4 entities and 13 semantic relations is defined, and a corpus of more than 1500 sentences from different factual sources~(i.e., Spanish Medline articles, Spanish Wikinews articles, and English biomedical preprints related to COVID-19) is annotated.
Two computational tasks are defined: the detection of multi-span, non-contiguous, and potentially overlapping named entities; and the detection of semantic relations between them.
A shared annotation campaign was organized, where a total of 9 participants presented 10 different systems with varied levels of performance.

The eHealth-KD task focuses on cross-domain, multi-lingual and low-resource solutions. This setting presents a significant challenge to existing state-of-the-art methods, which often rely on large amounts of training data.
A succesful approach to the eHealth-KD must leverage transfer learning across different domains and languages, since the vast majority of the training examples are provided in Spanish language and from the Medline domain, while only a small development set is available in the remaining settings.
With this added complexity, we expect to encourage solutions that can be deployed in low-resource environments, where is unfeasible to train large language models over longs periods of time.

The remaining of this paper is organized as follows.
Section~\ref{sec:task} describes the eHealth-KD tasks in greater detail, including the annotation model and performance metrics.
Section~\ref{sec:resources} describes the corpora and other resources created for this challenge and presents some qualitative analysis of their characteristics.
Section~\ref{sec:systems} describes the different systems presented in the challenge and summarises the main approaches and most common characteristics they share.
Section~\ref{sec:results} presents the main results of the challenge.
Section~\ref{sec:discussion} discusses the most interesting insights of the challenge and highlights both the most relevant lessons learned and potential improvements for future similar endeavours.

\section{Tasks Descriptions}\label{sec:task}

The eHealth-KD challenge consists on the automatic sentence-level annotation
of multi-token entities and binary relations among them.

A custom annotation model has been defined, comprising 4 entity types and 13 relations,
that attempts to capture a large part of factual semantics in technical documents,
including enciclopedias, news, and scientific papers.

The annotation model is explained in detail in \namecite{piad2019general}.

A brief explanation is presented next.

-- Explicar las entidades y relaciones como siempre.

The challenge has been divided into two different subtasks:
entity recognition and relation extraction.

To evaluate each subtask, we count correct, partial, missing, and spurious
annotations, and weight them according to an $F_1$ measure, independently per task.

-- Fórmulas

Furthermore, the challenge is graded in three different scenarios:
one for each subtask and one where both subtasks are performed in sequence.
This is the main scenario, which ultimately decides the winner of the challenge,
although all other results are interesting.

\section{Corpora and Resources}\label{sec:resources}

The Challenge is based on a corpus of documents composed of
sentences taken from previous challenges and other resources,
and newly annotated sentences.

Three different sources of textual information are sampled: medline articles,
wikinews articles, and biomedical papers from the CORD-19 corpus.

The medline and wikinews articles are in Spanish, while CORD are in English.

From the 2019 and 2020 challenges, X sentences where taken.

For this new edition, Y sentences were annotated by a team of annotators.
The team composition is 4 junior annotators and 3 senior annotators.
2 junior annotators annotated each sentence, and a senior annotator performed the merging.

The newly annotated sentences are used solely for evaluation purposes,
while all training and development resources are reused from previous challenges.

Overall, the composition of the corpus is presented in Table~\ref{tab:corpus}.

\begin{table}
  \caption{Composition of the corpus, highlighting resources from previous
  challenges and newly annotated sentences.\label{tab:corpus}}
\end{table}

\section{Systems Descriptions}\label{sec:systems}

The challenge caught the attention of 8 participants from across the globe,
who presented a variety of approaches clustered around deep learning architectures.
Table~\ref{tab:participants} summarises the main characteristics of each approach presented.
A brief summary of each system follows:

\begin{table*}[ht]
  \centering
  \begin{tabularx}{\textwidth}{lXllll}
    \toprule
    System & Features & Tasks & Subtask A & Subtask B & Multi-span \\
    \midrule
    Codestrange & 				 \\
    GuanZhengyi & BETO & Only A & Sequence & - & BIO \\
    IXA & ROBERTa & Sequential & Sequence & Sequence & BIO \\
    JAD & BERT & Joint & Token & Pairwise & Relation \\
    Maoqin & BERT & Only A & Sequence & - & BIO \\
    PUCRJ-PUCPR-UFMG & BERT & Joint & Sequence & Pairwise & BIO \\
    uhKD4 & Word2vec POS-tag Character Position & Sequential & Sequence & Pairwise & BILOUV \\
    UH-MMM & BERT FastText POS-tag Dependency Character & Sequential & Sequence & Pairwise & BILOUV \\
    Vicomtech Joint & BERT & Joint & Sequence & Pairwise & BIO \\
    Vicomtech Seq2Seq & T5 & Joint & Text2text & Text2text & Text \\
    \bottomrule
  \end{tabularx}
  \caption{Summary of the approaches presented at the eHealth-KD Challenge.\label{tab:participants}}
\end{table*}

%-- Describir los sistemas
\begin{description}
  \item[Team Codestrange] proposes

  \item[Team GuanZhengy~\cite{guanzhengyi}] presents a traditional NER architecture for Subtask A, based on contextual embeddings from a BETO pre-trained language model, and a combination of Convolutional, Bi-LSTM, and CRF layers for decoding BIO tags.

  \item[Team IXA~\cite{ixa}] models both substasks are sequence labeling problems encoded with a BIO system and using a pre-trained XLM-RoBERTa language model. Subtask A is solved with a standard NER architecture. For Subtask B, they solve a sequence labelling problem for each pair of entities, where tags correspond to relation labels.

  \item[Team JAD~\cite{jad}] proposes a single model based on BERT pre-trained embeddings that jointly outputs entity labels~(at token level) and pairwise relation labels. To deal with multi-span entities, they add a virtual relation that links tokens from the same entity.

  \item[Team Maoquin~\cite{maoquin}] presents a traditional NER architecture based on BERT pre-trained embeddings and BIO tags for Subtask A, combined with Bi-LSTM and CRF layers.

  \item[Team PUCRJ-PUCPR-UFMG~\cite{pucrj}] proposes a joint model that outputs token labels~(modelled as a sequence labelling problem) and pairwise relation labels, based on BERT pre-trained embeddings as the main feature.

  \item[Team uhKD4~\cite{uhkd4}] models both subtasks sequentially, using a standard NER architecture with BILOUV encoding for Subtask A and a pairwise classification model for Subtask B. As features, they employ a variety of syntactic characteristics~(POS-tags, character embeddings, positional embeddings) as well as word2vec embeddings.

  \item[Team UH-MMM~\cite{uhmmm}] also models both subtasks sequentially, using a standard NER architecture with BILOUV encoding for Subtask A and a pairwise classification model for Subtask B. As a key characteristic, they encode the shortest dependency path between two entities for the relation predction. They also compare several different embeddings, including health-specific and general-purpose approaches.

  \item[Team Vicomtech~\cite{vicomtech}] presents two different models. The first consists of a joint architecture for sequence labelling~(Subtask A) and pairwise relation prediciton~(Subtask B) based on BERT pre-trained embeddings. The second model is a text-to-text architecture, based on a T5 model, finetunned on a problem-specific encoding of the entities and relations that solves both subtasks in a single pass.
\end{description}

-- Describir ideas generales más usadas

How can see in the table \ref{} BERT and variants predominate as feature extractor although
some teams add clasic NLP featuures.
In contrast with previus years the join aproche is used by more than the half of system that present in the involve task
Como en años anteriores the subtask A is model as sequens labeling using some variant of BIO encoding. 
Likewise the subtask B is commonly model as pair wise classification.

Two approaches break this treads IXA and VICONTECH, The fisrt model the task B
also as sequence labeling reusing the same arquitecture that subtask A.
Th second present a arquitecture text to text that translate que raw sentence To
a semiestructured representation where are encode all the entities and their relations.

\section{Challenge Results}\label{sec:results}

Table~\ref{tab:results} summarizes the main results in the challenge.

\begin{table}
  \caption{Results.\label{tab:results}}
\end{table}

In Scenario 1, the best performing system is\dots

-- Describir los demás escenarios

\section{Discussion}\label{sec:discussion}

-- Ver los sistemas con sus features y qué features son mejores o peores en cada tarea

-- Comparar con los baselines en cada tarea, hasta qué nivel está resuelta cada tarea

-- Hablar brevemente de la evolución de los sistemas en las 4 ediciones,
cómo se han ido moviendo hacia transformers

-- Hablar de la modelación de las entidades y relaciones como tareas separadas,
la desventaja que puede representar eso porque los sistemas que han ganado hacen
ambas cosas a la vez, o sea hay representación conjunta que es válida

-- Hablar de las relaciones como problema binario, que no tiene en cuenta que ciertas
relaciones implican posiblemente la aparición de otras.

-- Hablar de que el orden en que el humano anota no es el mismo que un sistema,
y que si se pudiera aprender algo de esto, dar con el dataset no solo las anotaciones
sino en qué orden fueron realizadas.

-- Hablar de la necesidad de cambiar de tareas hacia algo que refleje el valor
del conocimiento extraído, como question answering.

\section{Conclusions}\label{sec:conclusions}

\section*{Acknowledgments}

\bibliographystyle{fullname}
\bibliography{bibliography}

\end{document}
